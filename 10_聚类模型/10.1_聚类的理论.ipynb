{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98d1ddb6-7679-43d5-ac0f-1b81b3ee5cd1",
   "metadata": {},
   "source": [
    "# 10.1 聚类的理论\n",
    "聚类是一种无监督的学习，它将相似的对象归到同一个簇中。簇内的对象越相似，聚类的效果越好。\n",
    "该算法可以应用于客户价值分析、文本分类、基因识别、卫星图片分析、商业客户归类等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d512e-fdaf-4cfc-bb91-683cf2ed95e4",
   "metadata": {},
   "source": [
    "## 1. 聚类和分类的不同\n",
    "聚类和分类的最大不同在于，分类的目标事先已知，而聚类则不一样。因为其产生的结果与分类相同，只是没有预先定义，聚类有时候也被称为无监督分类（unsupervised classification）。\n",
    "\n",
    "**聚类(Clustering)** ：是指把相似的数据划分到一起，具体划分的时候并不关心这一类的标签，目标就是把相似的数据聚合到一起，聚类是一种无监督学习(Unsupervised Learning)方法。\n",
    "\n",
    "**分类(Classification)** ：是把不同的数据划分开，其过程是通过训练数据集获得一个分类器，再通过分类器去预测未知数据，分类是一种监督学习(Supervised Learning)方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac55e86d-6549-496a-a36b-06c98fc5e663",
   "metadata": {},
   "source": [
    "## 2. K-均值（K-Means）算法设计\n",
    "K均值（K-means）算法是一种常用的聚类算法，用于将数据点划分成 K 个不同的组或簇。\n",
    "K是指聚类的类别数量。被归为一类的数据点组成一个簇(cu第四声)。\n",
    "请问图中的K=？\n",
    "\n",
    "![K-Means](images/K-Means.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24a62a2-e1ee-443a-bee0-d9386d150d37",
   "metadata": {},
   "source": [
    "### 2.1 算法步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972fd60b-3b51-401f-9bcc-8f9a9ddb7a1a",
   "metadata": {},
   "source": [
    "该算法的基本思想是将数据点划分为 K 个簇，使得每个数据点都属于离它最近的簇的中心（质心）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228ca304-6440-4260-b4e7-c1e28a3a9012",
   "metadata": {},
   "source": [
    "K均值(K-means)算法分为3个步骤：  \n",
    "- **第1步，选择初始的簇中心，可以随机选择数据集中的样本；**  \n",
    "- **第2步，使用相似度算法，计算样本和每个簇中心的距离，将每个样本分配到最近的簇中心所在的簇；**  \n",
    "- **第3步，计算新的簇中心。**  \n",
    "- **重复迭代第2和3步，直到簇中心不再变化或达到最大迭代次数为止。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac3a168-8664-4b11-9412-37eaab221d93",
   "metadata": {},
   "source": [
    "在第2步中，相似对象归入同一簇，将不相似对象归到不同簇。相似这一概念取决于所选的相似度计算方法。\n",
    "\n",
    "![distance_algo](images/distance_algo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0115a9e-0de4-4ea1-8665-7c8874b61a41",
   "metadata": {},
   "source": [
    "在第3步中，如何计算簇的中心呢？我们考虑最简单的三个点组成的三角形的中心。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875b3ac3-3652-4814-85e7-bf6bb3d19a1e",
   "metadata": {},
   "source": [
    "![triangle](images/triangle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90704e7b-0577-4a80-90fa-1492e08b4a67",
   "metadata": {},
   "source": [
    "三角形的质心公式： 如果三角形顶点的坐标为 A($x_1$, $y_1$), B($x_2$, $y_2$), C($x_3$, $y_3$)， 则三角形质心的公式如下： 三角形的质心= $((x_1+x_2+x_3)/3, (y_1+y_2+y_3)/3)$。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f515e20-9e3d-4c62-bd71-88c51aa76ff2",
   "metadata": {},
   "source": [
    "所以，如果数据是二维的，对于每个簇 $C_i$，其质心 $centroid_i$ ，那么质心的计算公式为：\n",
    "\n",
    "\n",
    "\n",
    "$$ \n",
    "\\text{centroid}_i = \\left( \\frac{\\sum_{j=1}^{n} x_{ij}}{n}, \\frac{\\sum_{j=1}^{n} y_{ij}}{n} \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "其中，$x_{ij}$ 和 $y_{ij}$ 分别表示簇 $C_i$ 中第 $j$ 个数据点的横纵坐标，$n$ 是簇 $C_i$ 中数据点的数量。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0c3ce8-0b31-47d1-96a7-513b7bfed4f9",
   "metadata": {},
   "source": [
    "如果数据是多维的，那么质心的计算公式可以推广为：\n",
    "\n",
    "$$\n",
    "\\text{centroid}_i = \\left( \\frac{\\sum_{j=1}^{n} x_{ij}}{n}, \\frac{\\sum_{j=1}^{n} y_{ij}}{n}, \\ldots, \\frac{\\sum_{j=1}^{n} d_{ij}}{n} \\right) \n",
    "$$\n",
    "\n",
    "其中，$x_{ij}$、$y_{ij}$、$\\ldots$、$d_{ij}$ 表示簇 $C_i$ 中第 $j$ 个数据点的各个特征值，$n$ 是簇 $C_i$ 中数据点的数量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0176e39-eb8d-466f-b17e-03e99f827929",
   "metadata": {},
   "source": [
    "### 2.2 动态演示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed60f02-adc7-463e-9ee1-ce69d8c30dee",
   "metadata": {},
   "source": [
    "下面是K-Means算法的动态演示。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877354e6-08c1-4275-b71f-548cb5d1ad86",
   "metadata": {},
   "source": [
    "![algo](images/algo.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0594475a-43b4-4011-994e-ed54f9ed875f",
   "metadata": {},
   "source": [
    "### 2.3 K-均值算法的优缺点\n",
    "优点：步骤简单，使用编程语言容易实现。\n",
    "\n",
    "缺点：\n",
    "1. K-means算法中的k是事先给定的，但是往往对于k给多少难以估计\n",
    "\n",
    "2. 受初始点的位置影响大，尤其是当部分样本点为异常点的时候"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2da768-2b12-408e-a85e-8ecb4adfb697",
   "metadata": {},
   "source": [
    "## 3. 聚类算法家族\n",
    "当然，聚类算法不止K-Means一种。当数据集本身情况比较复杂，使得K-means聚类效果并不理想的时候，很多新的聚类算法被开发出来了。\n",
    "### 3.1 DBSCAN\n",
    "k-means算法对于凸性数据具有良好的效果，能够根据距离来讲数据分为球状类的簇，但对于非凸形状的数据点，就无能为力了，当k-means算法在环形数据的聚类时，我们看看会发生什么情况。\n",
    "\n",
    "![K-Means非凸](images/K-Means-feitu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c197a0ae-9800-485c-bbb6-bb6da8859b71",
   "metadata": {},
   "source": [
    "从上图可以看到，kmeans聚类产生了错误的结果，这个时候就需要用到基于密度的聚类方法了。\n",
    "\n",
    "DBSCAN（Density-Based Spatial Clustering of Applications with Noise）是一种基于密度的聚类算法，适用于发现任意形状的簇，并能够有效地处理噪声数据。DBSCAN的基本思想是通过确定数据点周围的密度来识别簇。与K均值等算法不同，DBSCAN不需要事先指定要形成的簇的数量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae75865b-26ca-416d-bb4f-ef280fe69799",
   "metadata": {},
   "source": [
    "<img src='images/DBSCAN.gif' width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42a5cc1-4aa1-4460-9eed-07e1d6686668",
   "metadata": {},
   "source": [
    "### 3.2 高斯混合\n",
    "高斯混合模型（Gaussian Mixture Model，GMM）可以看做是k-means模型的一个优化。它假设数据是由多个高斯分布组成的混合体，每个高斯分布代表一个簇。GMM的基本思想是将数据点看作是从多个高斯分布中抽样而来的，通过调整每个高斯分布的参数来最大化观测数据的似然性。\n",
    "\n",
    "GMM的概率密度函数是多个高斯分布的线性组合，表示为：\n",
    "\n",
    "$$ p(\\mathbf{x}) = \\sum_{k=1}^{K} \\pi_k \\mathcal{N}(\\mathbf{x} | \\boldsymbol{\\mu}_k, \\boldsymbol{\\Sigma}_k) \n",
    "$$\n",
    "\n",
    "其中，$p(\\mathbf{x})$ 是数据点 $\\mathbf{x}$ 的概率密度，$K$ 是高斯分布的数量，$\\pi_k$ 是每个高斯分布的权重（满足 $\\sum_{k=1}^{K} \\pi_k = 1$），$\\boldsymbol{\\mu}_k$ 和 $\\boldsymbol{\\Sigma}_k$ 分别是第 $k$ 个高斯分布的均值和协方差矩阵。\n",
    "\n",
    "\n",
    "<img src='images/GMM.gif' width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99649672-6434-4ed4-ad77-8ee0e099a41e",
   "metadata": {},
   "source": [
    "### 3.3 层次聚类\n",
    "层次的聚类方法（Hierarchical Clustering），从字面上理解，其是层次化的聚类，最终得出来的是树形结构。专业一点来说，层次聚类通过计算不同类别数据点间的相似度来创建一棵有层次的嵌套聚类树。\n",
    "\n",
    "其算法流程为：先将所有样本的每个点都看成一个簇，然后找出距离最小的两个簇进行合并，不断重复到预期簇或者其他终止条件。\n",
    "\n",
    "![HierarchicalClustering](images/HierarchicalClustering.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a8b472-edb2-488a-9bf8-47e856b79ece",
   "metadata": {},
   "source": [
    "## 练习\n",
    "请设计一个你的聚类算法，写在草稿纸上：\n",
    "\n",
    "1. 请包括算法的流程\n",
    "2. 解释你算法的优势  \n",
    "\n",
    "提示：可以从k-means算法的K和means下手"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb681233-952a-41f5-bc8d-e95f5e723d93",
   "metadata": {},
   "source": [
    "## 练习\n",
    "你是否已经掌握聚类算法理论？\n",
    "请完成自我检测：<a href=\"https://docs.qq.com/form/page/DWkhyV0ZQSVRtTElC\" target=\"_blank\">  https://docs.qq.com/form/page/DWkhyV0ZQSVRtTElC  </a> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ae0436-c2ab-4387-a24d-eda712c81830",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
