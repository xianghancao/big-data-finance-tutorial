{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e04f3a7f-2369-41d7-87af-236285fa09a3",
   "metadata": {},
   "source": [
    "# 附录：为什么当前是深度学习的时代？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ae2962-7315-484a-89b6-4f9ab71899ed",
   "metadata": {},
   "source": [
    "深度学习在计算机视觉领域的两个关键思想——卷积神经网络和反向传播——早在1990年就已经被充分理解。而对于时间序列的深度学习而言，长短期记忆（LSTM）算法于1997年开发出来，并且至今基本保持不变。那么，为什么深度学习直到2012年后才开始蓬勃发展？这两个十年间发生了什么变化呢？\n",
    "总的来说，机器学习的发展受到三个技术因素的推动：\n",
    "\n",
    "- 硬件\n",
    "- 数据集和基准\n",
    "- 算法进步\n",
    "\n",
    "\n",
    "由于这一领域的发展主要受到实验结果的指导，而非理论的支持，算法的进步只有在有适当的数据和硬件可用于尝试新思想（或扩展旧思想，这也是经常发生的情况）时才能实现。机器学习不像数学或物理学，可以用一支笔和一张纸完成重大进展。它是一门工程科学。\n",
    "在1990年代和2000年代，数据和硬件一直是真正的瓶颈。但是在此期间发生了以下变化：互联网迅速发展，高性能图形芯片应运而生，以满足游戏市场的需求。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d537eb-aa18-4e19-9280-ce7b0a80f8f4",
   "metadata": {},
   "source": [
    "### 硬件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f381ee-81cd-46e0-a1f0-ae321ab87b8c",
   "metadata": {},
   "source": [
    "在1990年至2010年期间，现成的中央处理器（CPU）的速度提高了大约5000倍。因此，现在可以在笔记本电脑上运行小型深度学习模型，而在25年前这是不可行的。\n",
    "\n",
    "但是，在计算机视觉或语音识别中使用的典型深度学习模型需要比您的笔记本电脑提供的计算能力高出数个数量级。在2000年代，像NVIDIA和AMD这样的公司投资了数十亿美元开发快速、大规模并行的芯片（图形处理单元或GPU），以提供越来越逼真的视频游戏图形——这些廉价、单一用途的超级计算机旨在实时渲染屏幕上的复杂3D场景。当时，这项投资也使科学界受益匪浅。2007年，NVIDIA推出了CUDA（https://developer.nvidia.com/about-cuda） 编程接口。少数几个GPU开始取代各种高度可并行化的应用程序中的大型CPU集群，从物理建模开始。深度神经网络主要由许多小矩阵乘法组成，也高度可并行化，因此在2011年左右，一些研究人员开始编写神经网络的CUDA实现，Dan Ciresan和Alex Krizhevsky是其中的先驱之一。\n",
    "\n",
    "事实证明，游戏市场为下一代人工智能应用程序提供了超级计算的补贴。有时，大事物的开始就是游戏。如今，NVIDIA Titan RTX是一款GPU，在2019年底的价格为2500美元，可以提供16 teraFLOPS的单精度峰值性能（每秒16万亿个float32操作）。这比1990年世界上最快的超级计算机Intel Touchstone Delta强大约500倍。在Titan RTX上，仅需几个小时即可训练出类似于2012年或2013年ILSVRC竞赛获胜模型的ImageNet模型。与此同时，大型公司在数百个GPU的集群上训练深度学习模型。\n",
    "\n",
    "此外，深度学习行业已经超越了GPU，并正在投资于越来越专业、高效的深度学习芯片。在2016年的年度I/O大会上，谷歌公布了其张量处理单元（TPU）项目：一种新的芯片设计，从头开始开发，以比顶级GPU更快、更节能地运行深度神经网络。今天，2020年，TPU卡的第三个版本代表着420 teraFLOPS的计算能力。这比1990年的Intel Touchstone Delta强大约1万倍。\n",
    "\n",
    "这些TPU卡设计成可以组装成大规模的配置，称为“Pods”。一个Pod（1024个TPU卡）的峰值性能为100 petaFLOPS。以IBM Summit在奥克岭国家实验室的当前最大超级计算机的峰值计算能力为例，Summit由27,000个NVIDIA GPU组成，峰值计算能力约为1.1 exaFLOPS，这个Pod的峰值计算能力大约为其的10%。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec38307d-1d1b-4bed-8f38-9ffb77780739",
   "metadata": {},
   "source": [
    "### 数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b85b29-045f-4291-893c-92e89817bede",
   "metadata": {},
   "source": [
    "人工智能有时被誉为新的工业革命。如果深度学习是这场革命的蒸汽机，那么数据就是它的煤炭：这种原材料为我们的智能机器提供动力，没有它就一无所能。在数据方面，除了过去20年存储硬件呈指数增长（遵循摩尔定律）之外，改变游戏规则的是互联网的崛起，使得收集和分发非常大型的机器学习数据集成为可能。如今，大型公司处理的图像数据集、视频数据集和自然语言数据集是通过互联网无法收集的。例如，Flickr上用户生成的图像标签一直是计算机视觉数据的宝库。YouTube视频也是如此。而维基百科是自然语言处理的关键数据集之一。\n",
    "\n",
    "如果说有一个数据集是深度学习崛起的催化剂，那就是ImageNet数据集，它包含了140万张图像，手工注释了1000个图像类别（每个图像一个类别）。但是ImageNet的特殊之处不仅仅在于它的规模之大，还有与之相关的年度竞赛。\n",
    "正如Kaggle自2010年以来一直在展示的那样，公开竞赛是激励研究人员和工程师突破极限的极好方式。研究人员竞争击败的共同基准有力地帮助了深度学习的崛起，突显了它相对于传统机器学习方法的成功。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f596ed78-a375-4be7-a2f6-fe18ce2ace32",
   "metadata": {},
   "source": [
    "### 算法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4e58b5-7f4b-4e34-a691-14ce63f297b3",
   "metadata": {},
   "source": [
    "除了硬件和数据之外，直到2000年代末，我们还缺乏一种可靠的方法来训练非常深的神经网络。因此，神经网络仍然相对较浅，只使用了一两层的表示；因此，它们无法与更精细的浅层方法（如支持向量机和随机森林）相提并论。关键问题在于梯度在深层堆叠中的传播。用于训练神经网络的反馈信号会随着层数的增加而逐渐消失。\n",
    "这在2009年至2010年左右发生了变化，当时出现了几项简单但重要的算法改进，使梯度传播更好：\n",
    "\n",
    "- 更好的神经网络层激活函数\n",
    "- 更好的权重初始化方案，从逐层预训练开始，然后很快就被抛弃了\n",
    "- 更好的优化方案，如RMSProp和Adam\n",
    "\n",
    "只有当这些改进开始允许训练具有10层或更多层的模型时，深度学习才开始发光。\n",
    "\n",
    "最后，在2014年、2015年和2016年，还发现了更先进的改进梯度传播的方法，如批归一化、残差连接和深度可分离卷积。\n",
    "\n",
    "如今，我们可以从头开始训练任意深的模型。这解锁了使用极其庞大的模型，这些模型具有相当丰富的表示能力，即编码非常丰富的假设空间。这种极端的可扩展性是现代深度学习的一个定义特征。大规模模型架构，具有数十层和数千万个参数，已经在计算机视觉（例如，ResNet、Inception或Xception等架构）和自然语言处理（例如，大型基于Transformer的架构，如BERT、GPT-3或XLNet）中带来了重要的进展。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
