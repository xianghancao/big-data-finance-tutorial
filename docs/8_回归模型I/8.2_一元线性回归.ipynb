{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63b90177-a6e2-4a4d-9246-71b2406dd6b0",
   "metadata": {},
   "source": [
    "# 8.2 一元线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a993a01-43cf-4aa8-9394-8f4e3e1eb162",
   "metadata": {},
   "source": [
    "一元线性回归是统计学中的一种线性回归模型，用于建立一个因变量（也称为响应变量、被解释变量）与一个自变量（也称为解释变量）之间的线性关系。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59df0bf8-3b53-43b7-94e0-c47372a963ab",
   "metadata": {},
   "source": [
    "## 1. 解释变量和被解释变量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb7545b-0145-4a7f-bdb7-6b99648044d3",
   "metadata": {},
   "source": [
    "一元线性回归的表达形式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ba9a0d-f677-4ca5-b66b-1b54337c4359",
   "metadata": {},
   "source": [
    "$$\n",
    "Y_i = \\beta_0+\\beta_1X_i+u_i \n",
    "$$\n",
    "\n",
    "$$\n",
    "i是第i次观测，i=1,2,...,n;Y_i是被解释变量，\\beta_0是截距；\\beta_1是总体回归线的斜率，u_i是误差项\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b78fb9-3ce7-4f5b-81d3-e9d70a44feaa",
   "metadata": {},
   "source": [
    "输出变量 $Y$ 被称为被解释变量、因变量、响应变量、结果，而输入变量 $X$ 可以被称为解释变量、自变量、预测因子。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f60222-0a01-4f54-ad3b-de9f34a4f4c4",
   "metadata": {},
   "source": [
    "## 2. 最小二乘法（OLS方法）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559987f1-1adc-40cd-8d9e-cca5ac14f3c5",
   "metadata": {},
   "source": [
    "线性回归拟合一个具有系数的线性模型，以最小化数据集内观测目标与线性逼近预测目标之间的残差平方和。数学上，它解决了这样一个问题:\n",
    "\n",
    "$$\n",
    "min\\{\\sum^{n}_{i=1}(Y-\\beta_0-\\beta_1X_i)^2\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe571ed-3eb3-4687-8a28-cc90fe26623a",
   "metadata": {},
   "source": [
    "![OLS](images/OLS.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449c32e5-486c-405f-b3a7-3da722329954",
   "metadata": {},
   "source": [
    "为了最小化预测误差平方和$\\sum^{n}_{i=1}(Y-\\beta_0-\\beta_1X_i)^2$，首先将该式关于$b_0$和$b_1$求偏导数，可以得到以下两个等式：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\sum(Y_i-\\beta_0-\\beta_1X_i)^2}{\\partial\\beta_0}\n",
    "= -2\\sum(Y_i-\\beta_0-\\beta_1X_i)^2\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\sum(Y_i-\\beta_0-\\beta_1X_i)^2}{\\partial\\beta_1}\n",
    "= -2\\sum(Y_i-\\beta_0-\\beta_1X_i)X_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcf5543-769d-4463-add1-c775e907e806",
   "metadata": {},
   "source": [
    "令上面2个偏导数等于零，整理后得到OLS估计量$\\beta_0$和$\\beta_1$必须满足的两个方程：\n",
    "\n",
    "$$\n",
    "\\bar{Y}-\\hat{\\beta_0}-\\hat{\\beta_1}\\bar{X}=0\n",
    "$$\n",
    "$$\n",
    "\\frac{1}{n}\\sum{X_i}{Y_i} - \\hat{\\beta_0}\\bar{X}-\\hat{\\beta_1}\\frac{1}{n}\\sum^n_{i=1}X^2_i = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d255dd-4a73-4867-8dbf-bb763531e50f",
   "metadata": {},
   "source": [
    "解上述关于$\\hat{\\beta_0}$和$\\hat{\\beta_1}$的方程组，得到\n",
    "\n",
    "$$\n",
    "\\hat{\\beta_1}=\\frac{\\frac{1}{n}\\sum_{i=1}^n X_i Y_i-\\bar{XY}}{\\frac{1}{n}\\sum_{i=1}^n X_i^2 - \\bar{X}^2}\n",
    "$$\n",
    "$$\n",
    "\\hat{\\beta_0} = \\bar{Y} - \\hat{\\beta_1}\\bar{X}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
